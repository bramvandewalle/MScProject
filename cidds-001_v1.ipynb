{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "47dc783c64eba16578308ded2496eecd3f77c9cbf1d7b090711421ceeb34a226"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NIDS on CIDDS-001 OpenStack data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the first two parts `Use KNN and RFC on CIDDS-001 OpenStack week 1` and `Use KNN and RFC on CIDDS-001 OpenStack week 2` the steps listed below are executed. When we have a k-Nearest Neigbors (KNN) and a Random Forest Classification (RFC) model for both week 1 and week 2, we mix the test data and the models in the final two sections `Use knn_week1 and rfc_week1 on test data of week 2` and `Use knn_week2 and rfc_week2 on test data of week 1`. The KNN and RFC model trained with data of week 1 is scored with test data of week 2. But, in order to be able to do this, we need to normalize the test data of week 2 with the `mean` and `std` parameters that were used on the training data of the models of week 1. Analogously, the same mix is executed for the models of week 2 with the test data of week 1.\n",
    "\n",
    "## 1. Preprocessing\n",
    "First, the data is preprocessed into a pandas DataFrame. The CIDDS-001 contains 14 columns: \n",
    "* Src IP\n",
    "* Src Port\n",
    "* Dest IP\n",
    "* Dest Port\n",
    "* Proto\n",
    "* Data first seen\n",
    "* Duration\n",
    "* Bytes\n",
    "* Packets\n",
    "* Flags\n",
    "* Class\n",
    "* AttackType\n",
    "* AttackID\n",
    "* AttackDescription\n",
    "\n",
    "But a few columns are not used for classification because we do not want our model to be dependent them. Following columns are dropped in the preprocessing step:\n",
    "* Src IP\n",
    "* Src Port\n",
    "* Dest IP\n",
    "* Data first seen\n",
    "* AttackType\n",
    "* AttackID\n",
    "* AttackDescription\n",
    "\n",
    "To be noted: in the dataset read from the files there was an extra column 'Flows' which always has the value '1' and is removed too.\n",
    "\n",
    "## 2. Split the preprocessed data into a training set and a test set\n",
    "After the preprocessing step, the preprocessed data is split into 80% training data and 20% test data.\n",
    "\n",
    "## 3. Normalize the data\n",
    "Each column (except for the `Flags`) is z-score normalized. The `mean` and `std` for each column of the training set are determined. The z-score calculation (i.e. unchanged `mean` and `std` for each column) is used on the corresponding column of the test set.\n",
    "\n",
    "Note that I deliberatly split the data into a training and test set _before_ normalizing. This is done because if the model would see new data, this new data must be normalized with the same `mean` and `std` as the training set was normalized with. To get a better representation of the score of the model, the same philosophy is adopted to the normalization process of the test data\n",
    "\n",
    "## 4. Train and score the models\n",
    "Finally, the normalized data can be used to train and test the model. This is done using the scikit-learn implementations of k-Nearest Neigbors and Random Forest Classification."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Questions: \n",
    "* What is the `flows` column in the cleaned data set?\n",
    "* If you normalize the dataset, how is new data handled? You must perform some kind of operation on the new data to map it into the dimensions used to train the model with. Should we use the same `Z-score` calculation but with `mean` and `std` used for training?\n",
    "* Cfr. question 2: we split the dataset into a training set and in a test set. Do we calculate `mean` and `std` only on the training set and use the same `mean` and `std` on the test set data to normalize it?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from timeit import default_timer as timer\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "from utils import cidds_001 as utils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Global timing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "global_start = timer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use KNN and RFC on CIDDS-001 OpenStack week 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset_week1 = pd.read_feather('saved_dfs/cidds-001/traffic/OpenStack/CIDDS-001-internal-week1-cleaned.feather')\r\n",
    "dataset_week1 = dataset_week1.sample(frac=1, random_state=13) # randomize dataset\r\n",
    "dataset_week1 = utils.get_balanced_cidds(dataset_week1, classification_target='class')\r\n",
    "\r\n",
    "\r\n",
    "# For this first version, the classification target is 'class' (i.e. normal, victim, attack) instead of the better target 'attack_type' (cfr. v2)\r\n",
    "columns_to_drop = utils.columns_to_drop + ['attack_type']\r\n",
    "columns_to_drop.remove('class')\r\n",
    "dataset_week1.drop(columns=columns_to_drop, inplace=True)\r\n",
    "\r\n",
    "dataset_week1.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   duration  icmp  igmp  tcp  udp  src_port  dst_port  packets  bytes  flows  \\\n",
       "0     0.005   0.0   0.0  1.0  0.0   60543.0      80.0      5.0  479.0    1.0   \n",
       "1     0.007   0.0   0.0  1.0  0.0   54182.0      80.0      5.0  479.0    1.0   \n",
       "2     0.006   0.0   0.0  1.0  0.0   44446.0      80.0      5.0  479.0    1.0   \n",
       "3     0.008   0.0   0.0  1.0  0.0   58773.0      80.0      5.0  479.0    1.0   \n",
       "4     0.003   0.0   0.0  1.0  0.0   42573.0      80.0      6.0  545.0    1.0   \n",
       "\n",
       "   tcp_urg  tcp_ack  tcp_psh  tcp_rst  tcp_syn  tcp_fin  tos     class  \n",
       "0      0.0      1.0      1.0      0.0      1.0      1.0  0.0  attacker  \n",
       "1      0.0      1.0      1.0      0.0      1.0      1.0  0.0  attacker  \n",
       "2      0.0      1.0      1.0      0.0      1.0      1.0  0.0  attacker  \n",
       "3      0.0      1.0      1.0      0.0      1.0      1.0  0.0  attacker  \n",
       "4      0.0      1.0      1.0      0.0      1.0      1.0  0.0  attacker  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>icmp</th>\n",
       "      <th>igmp</th>\n",
       "      <th>tcp</th>\n",
       "      <th>udp</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>packets</th>\n",
       "      <th>bytes</th>\n",
       "      <th>flows</th>\n",
       "      <th>tcp_urg</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_psh</th>\n",
       "      <th>tcp_rst</th>\n",
       "      <th>tcp_syn</th>\n",
       "      <th>tcp_fin</th>\n",
       "      <th>tos</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60543.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54182.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44446.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58773.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42573.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the data in a training and test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "y_week1 = dataset_week1['class'].values\r\n",
    "x_week1 = dataset_week1.drop(['class'], axis=1)\r\n",
    "x_train_week1, x_test_week1, y_train_week1, y_test_week1 = train_test_split(x_week1, y_week1, test_size=0.6, random_state=0)\r\n",
    "\r\n",
    "print(len(x_train_week1))\r\n",
    "print(len(x_test_week1))\r\n",
    "print(len(y_train_week1))\r\n",
    "print(len(y_test_week1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "833271\n",
      "1249908\n",
      "833271\n",
      "1249908\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalize the training data and use same `mean` and `std` for test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "norm_params_week1 = utils.z_score_normalization(x_train_week1, utils.columns_to_normalize, cidds_df_test=x_test_week1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "knn_week1 = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\r\n",
    "\r\n",
    "start = timer()\r\n",
    "knn_week1.fit(x_train_week1, y_train_week1)\r\n",
    "end = timer()\r\n",
    "print('Time to fit KNN on week1 of OpenStack: {} seconds'.format(end - start))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\r\n",
    "score = knn_week1.score(x_test_week1, y_test_week1)\r\n",
    "end = timer()\r\n",
    "print('Scoring KNN took {0} seconds, with a score of {1}'.format(end - start, score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scoring KNN took 121.79406480000034 seconds, with a score of 0.9976718323719308\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrix of KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict\r\n",
    "predicted_y = knn_week1.predict(x_test_week1)\r\n",
    "\r\n",
    "# calculate confucion matrix\r\n",
    "confusion_matrix(y_test_week1, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit RFC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfc_week1 = RandomForestClassifier(n_estimators=200)\r\n",
    "\r\n",
    "start = timer()\r\n",
    "rfc_week1.fit(x_train_week1, y_train_week1)\r\n",
    "end = timer()\r\n",
    "print('Time to fit RFC on week1 of OpenStack: {} seconds'.format(end - start))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time to fit RFC on week1 of OpenStack: 61.51200289999997 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score RFC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\r\n",
    "score = rfc_week1.score(x_test_week1, y_test_week1)\r\n",
    "end = timer()\r\n",
    "print('Scoring RFC took {0} seconds, with a score of {1}'.format(end - start, score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scoring RFC took 2.5530915999997887 seconds, with a score of 0.9984398876719124\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrix of RFC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict\r\n",
    "predicted_y = rfc_week1.predict(x_test_week1)\r\n",
    "\r\n",
    "# calculate confucion matrix\r\n",
    "confusion_matrix(y_test_week1, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use KNN and RFC on CIDDS-001 OpenStack week 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_week2 = pd.read_feather('saved_dfs/cidds-001/traffic/OpenStack/CIDDS-001-internal-week2-cleaned.feather')\r\n",
    "dataset_week2 = dataset_week2.sample(frac=1, random_state=13) # randomize dataset\r\n",
    "dataset_week2 = utils.get_balanced_cidds(dataset_week2, classification_target='class')\r\n",
    "\r\n",
    "dataset_week2.drop(columns=columns_to_drop, inplace=True)\r\n",
    "\r\n",
    "dataset_week2.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   duration  icmp  igmp  tcp  udp  dst_port  packets  bytes  flag1  flag2  \\\n",
       "0     0.176   0.0   0.0  1.0  0.0     443.0      9.0  950.0    0.0    1.0   \n",
       "1     0.000   0.0   0.0  1.0  0.0      80.0      1.0   55.0    0.0    1.0   \n",
       "2     0.000   0.0   0.0  1.0  0.0      80.0      1.0   66.0    0.0    1.0   \n",
       "3     0.999   0.0   0.0  1.0  0.0   58848.0      4.0  216.0    0.0    1.0   \n",
       "4     0.000   0.0   0.0  1.0  0.0      80.0      1.0   66.0    0.0    1.0   \n",
       "\n",
       "   flag3  flag4  flag5  flag6   tos   class  \n",
       "0    1.0    0.0    1.0    0.0   0.0  normal  \n",
       "1    0.0    0.0    0.0    0.0   0.0  normal  \n",
       "2    0.0    0.0    0.0    0.0   0.0  normal  \n",
       "3    0.0    0.0    0.0    1.0  32.0  normal  \n",
       "4    0.0    0.0    0.0    0.0   0.0  normal  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>icmp</th>\n",
       "      <th>igmp</th>\n",
       "      <th>tcp</th>\n",
       "      <th>udp</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>packets</th>\n",
       "      <th>bytes</th>\n",
       "      <th>flag1</th>\n",
       "      <th>flag2</th>\n",
       "      <th>flag3</th>\n",
       "      <th>flag4</th>\n",
       "      <th>flag5</th>\n",
       "      <th>flag6</th>\n",
       "      <th>tos</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58848.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the data in a training and test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_week2 = dataset_week2['class'].values\r\n",
    "x_week2 = dataset_week2.drop(['class'], axis=1)\r\n",
    "x_train_week2, x_test_week2, y_train_week2, y_test_week2 = train_test_split(x_week2, y_week2, test_size=0.2, random_state=0)\r\n",
    "\r\n",
    "print(len(x_train_week2))\r\n",
    "print(len(x_test_week2))\r\n",
    "print(len(y_train_week2))\r\n",
    "print(len(y_test_week2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "637219\n",
      "159305\n",
      "637219\n",
      "159305\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalize the training data and use same `mean` and `std` for test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "norm_params_week2 = utils.z_score_normalization(x_train_week2, utils.columns_to_normalize, cidds_df_test=x_test_week2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn_week2 = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\r\n",
    "\r\n",
    "start = timer()\r\n",
    "knn_week2.fit(x_train_week2, y_train_week2)\r\n",
    "end = timer()\r\n",
    "print('Time to fit KNN on week2 of OpenStack: {} seconds'.format(end - start))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time to fit KNN on week2 of OpenStack: 678.3605799999996 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\r\n",
    "score = knn_week2.score(x_test_week2, y_test_week2)\r\n",
    "end = timer()\r\n",
    "print('Scoring KNN took {0} seconds, with a score of {1}'.format(end - start, score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scoring KNN took 193.8710618 seconds, with a score of 0.9976711339882615\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrix of KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict\r\n",
    "predicted_y = knn_week2.predict(x_test_week2)\r\n",
    "\r\n",
    "# calculate confucion matrix\r\n",
    "confusion_matrix(y_test_week2, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit RFC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfc_week2 = RandomForestClassifier(n_estimators=200)\r\n",
    "\r\n",
    "start = timer()\r\n",
    "rfc_week2.fit(x_train_week2, y_train_week2)\r\n",
    "end = timer()\r\n",
    "print('Time to fit RFC on week2 of OpenStack: {} seconds'.format(end - start))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time to fit RFC on week2 of OpenStack: 85.87605560000065 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score RFC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\r\n",
    "score = rfc_week2.score(x_test_week2, y_test_week2)\r\n",
    "end = timer()\r\n",
    "print('Scoring RFC took {0} seconds, with a score of {1}'.format(end - start, score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scoring RFC took 3.253232200000639 seconds, with a score of 0.9984181287467436\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrix of RFC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict\r\n",
    "predicted_y = rfc_week2.predict(x_test_week2)\r\n",
    "\r\n",
    "# calculate confucion matrix\r\n",
    "confusion_matrix(y_test_week2, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use `knn_week1` and `rfc_week1` on test data of week 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalize data of week 2 with normalization parameters of week 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test data of week 2, normalized with parameters of week 1\r\n",
    "x_test_week2_all = pd.DataFrame(data=x_week2, copy=True)\r\n",
    "utils.z_score_normalizations_with_given_params(x_test_week2_all, utils.columns_to_normalize, norm_params_week1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest Neighbors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\r\n",
    "score = knn_week1.score(x_test_week2_all, y_week2)\r\n",
    "end = timer()\r\n",
    "print('Scoring KNN took {0} seconds, with a score of {1}'.format(end - start, score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scoring KNN took 164.78324620000058 seconds, with a score of 0.9918709393929883\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict\r\n",
    "predicted_y = knn_week1.predict(x_test_week2_all)\r\n",
    "\r\n",
    "# calculate confucion matrix\r\n",
    "confusion_matrix(y_week2, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\r\n",
    "score = rfc_week1.score(x_test_week2_all, y_week2)\r\n",
    "end = timer()\r\n",
    "print('Scoring RFC took {0} seconds, with a score of {1}'.format(end - start, score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scoring RFC took 3.347298800000317 seconds, with a score of 0.9915131351809422\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict\r\n",
    "predicted_y = rfc_week1.predict(x_test_week2_all)\r\n",
    "\r\n",
    "# calculate confucion matrix\r\n",
    "confusion_matrix(y_week2, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use `knn_week2` and `rfc_week2` on test data of week 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalize data of week 1 with normalization parameters of week 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# test data of week 1, normalized with parameters of week 2\r\n",
    "x_test_week1_all = pd.DataFrame(data=x_week1, copy=True)\r\n",
    "utils.z_score_normalizations_with_given_params(x_test_week1_all, utils.columns_to_normalize, norm_params_week2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest Neighbors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\r\n",
    "score = knn_week2.score(x_test_week1_all, y_week1)\r\n",
    "end = timer()\r\n",
    "print('Scoring KNN took {0} seconds, with a score of {1}'.format(end - start, score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scoring KNN took 127.10119400000076 seconds, with a score of 0.97488619180581\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict\r\n",
    "predicted_y = knn_week2.predict(x_test_week1_all)\r\n",
    "\r\n",
    "# calculate confucion matrix\r\n",
    "confusion_matrix(y_week1, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = timer()\r\n",
    "score = rfc_week2.score(x_test_week1_all, y_week1)\r\n",
    "end = timer()\r\n",
    "print('Scoring RFC took {0} seconds, with a score of {1}'.format(end - start, score))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scoring RFC took 2.5423682999999073 seconds, with a score of 0.9733100783256394\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confusion matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predict\r\n",
    "predicted_y = rfc_week2.predict(x_test_week1_all)\r\n",
    "\r\n",
    "# calculate confucion matrix\r\n",
    "confusion_matrix(y_week1, predicted_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Global timing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "global_end = timer()\r\n",
    "print('Running the complete notebook took {0} min, {1} sec.'.format(\r\n",
    "    int((global_end - global_start) / 60), \r\n",
    "    int((((global_end - global_start) / 60) - int((global_end - global_start) / 60)) * 60)\r\n",
    "))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running the complete notebook took 28 min, 55 sec.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature importance of Random Forest Classification models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfc_week1.feature_importances_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([6.44247733e-02, 1.94160945e-01, 1.43496944e-01, 1.57513757e-01,\n",
       "       4.81383819e-02, 3.22431936e-03, 3.55890653e-06, 4.99891961e-03,\n",
       "       9.05759644e-03, 0.00000000e+00, 2.68939116e-02, 8.29083331e-02,\n",
       "       3.31036075e-02, 1.35006348e-01, 9.70686035e-02])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rfc_week2.feature_importances_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([6.99647245e-02, 1.35643158e-01, 2.03805422e-01, 1.74121280e-01,\n",
       "       2.42297710e-02, 1.41759086e-03, 2.84182600e-07, 4.55438387e-03,\n",
       "       5.30377735e-03, 0.00000000e+00, 1.48364935e-02, 1.01041198e-01,\n",
       "       1.55752075e-02, 1.47275489e-01, 1.02231221e-01])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  }
 ]
}