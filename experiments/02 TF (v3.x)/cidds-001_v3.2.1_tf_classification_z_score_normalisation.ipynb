{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bram_\\home\\msc\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single flow - Multi Layer Perceptron classification of CIDDS-001 OpenStack data\n",
    "The implementation is based on the paper **Intelligent Cyber Attack Detetion and Classification for Network-Based Intrusion Detection Systems**. However, the training data that was used is now balanced. The data of the first and second week are joined together to obtain the biggest possible dataset to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import cidds_001 as utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and shuffle week1\n",
    "week1 = pd.read_feather('saved_dfs/cidds-001/traffic/OpenStack/CIDDS-001-internal-week1-cleaned.feather')\n",
    "week1 = week1.sample(frac=1, random_state=13).reset_index(drop=True)\n",
    "\n",
    "# load and shuffle week2\n",
    "week2 = pd.read_feather('saved_dfs/cidds-001/traffic/OpenStack/CIDDS-001-internal-week2-cleaned.feather')\n",
    "week2 = week2.sample(frac=1, random_state=13).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess datasets\n",
    "* Both datasets week1 and week2 are used to obtain as much malicous traffic of the underrepresented attack types as possible.\n",
    "* Split the features and labels of the new dataset and encode the labels with one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1_benign = week1.where(week1['attack_type'] == '---').dropna()\n",
    "week1_portScan = week1.where(week1['attack_type'] == 'portScan').dropna()\n",
    "week1_dos = week1.where(week1['attack_type'] == 'dos').dropna()\n",
    "week1_pingScan = week1.where(week1['attack_type'] == 'pingScan').dropna()\n",
    "week1_bruteForce = week1.where(week1['attack_type'] == 'bruteForce').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(week1_benign) = 7010897\n",
      "len(week1_portScan) = 183511\n",
      "len(week1_dos) = 1252127\n",
      "len(week1_pingScan) = 3359\n",
      "len(week1_bruteForce) = 1626\n"
     ]
    }
   ],
   "source": [
    "print(f'len(week1_benign) = {len(week1_benign)}')\n",
    "print(f'len(week1_portScan) = {len(week1_portScan)}')\n",
    "print(f'len(week1_dos) = {len(week1_dos)}')\n",
    "print(f'len(week1_pingScan) = {len(week1_pingScan)}')\n",
    "print(f'len(week1_bruteForce) = {len(week1_bruteForce)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "week2_benign = week2.where(week2['attack_type'] == '---').dropna()\n",
    "week2_portScan = week2.where(week2['attack_type'] == 'portScan').dropna()\n",
    "week2_dos = week2.where(week2['attack_type'] == 'dos').dropna()\n",
    "week2_pingScan = week2.where(week2['attack_type'] == 'pingScan').dropna()\n",
    "week2_bruteForce = week2.where(week2['attack_type'] == 'bruteForce').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(week2_benign) = 8515329\n",
      "len(week2_portScan) = 82407\n",
      "len(week2_dos) = 1706900\n",
      "len(week2_pingScan) = 2731\n",
      "len(week2_bruteForce) = 3366\n"
     ]
    }
   ],
   "source": [
    "print(f'len(week2_benign) = {len(week2_benign)}')\n",
    "print(f'len(week2_portScan) = {len(week2_portScan)}')\n",
    "print(f'len(week2_dos) = {len(week2_dos)}')\n",
    "print(f'len(week2_pingScan) = {len(week2_pingScan)}')\n",
    "print(f'len(week2_bruteForce) = {len(week2_bruteForce)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat(\n",
    "    [\n",
    "        week1_pingScan, week2_pingScan, # use all pingScan flows of both wee1 and week2\n",
    "        week1_bruteForce, week2_bruteForce, # use all bruteForce flows of both week1 and week2\n",
    "        week1_benign.sample(frac=1, random_state=13).head(3000), # but use a small random sample of data of all other attack types\n",
    "        week2_benign.sample(frac=1, random_state=13).head(3000),\n",
    "        week1_dos.sample(frac=1, random_state=13).head(3000),\n",
    "        week2_dos.sample(frac=1, random_state=13).head(3000),\n",
    "        week1_portScan.sample(frac=1, random_state=13).head(3000),\n",
    "        week2_portScan.sample(frac=1, random_state=13).head(3000),\n",
    "    ]\n",
    ").sample(frac=1, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset) = 29082\n"
     ]
    }
   ],
   "source": [
    "print(f'len(dataset) = {len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attack_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>---</th>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bruteForce</th>\n",
       "      <td>4992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dos</th>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pingScan</th>\n",
       "      <td>6090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portScan</th>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "attack_type       \n",
       "---           6000\n",
       "bruteForce    4992\n",
       "dos           6000\n",
       "pingScan      6090\n",
       "portScan      6000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset.groupby(by='attack_type').size(), columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = dataset.drop(columns=utils.columns_to_drop + ['attack_type'])\n",
    "data_y = pd.get_dummies(dataset['attack_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noramalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = utils.z_score_normalization(data_x, utils.columns_to_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and compile the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(16,)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train.to_numpy()\n",
    "y = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1.3160 - accuracy: 0.5514\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.8697 - accuracy: 0.7642\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.8034\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.8244\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8428\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8564\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3641 - accuracy: 0.8633\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8711\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8757\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8824\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3173 - accuracy: 0.8809\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8854\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3035 - accuracy: 0.8891\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2979 - accuracy: 0.8916\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8947\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 0.8949\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2846 - accuracy: 0.8972\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.8992\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2764 - accuracy: 0.9019\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.9016\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.9032\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2640 - accuracy: 0.9073\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.9066\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.9071\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.9103\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.9114\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2567 - accuracy: 0.9117\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.9144\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.9128\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9160\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.9139\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9171\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.9167\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2391 - accuracy: 0.9191\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9200\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9210\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9206\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9203\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9222\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9257\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.9233\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9243\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9256\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.9250\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9260\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9275\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9308\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2169 - accuracy: 0.9284\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9280\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22353f1d940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x, y=y,\n",
    "          batch_size=1024,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the fitted model with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_test.to_numpy()\n",
    "y = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 - 0s - loss: 0.2037 - accuracy: 0.9347\n",
      "\n",
      "Test accuracy: 0.9346742033958435\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x,  y, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a confusion matrix for the predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lbl = np.argmax(y, axis=1)\n",
    "pred_y_lbl = np.argmax(pred_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[1093,   86,   16,   11,    4],\n",
       "       [  13,  989,    0,    5,   11],\n",
       "       [   0,    0, 1158,    0,    0],\n",
       "       [  28,   32,    0, 1170,    2],\n",
       "       [  12,  120,    0,   40, 1027]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(labels=y_lbl, predictions=pred_y_lbl, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of data_y (and confusion matrix): Index(['---', 'bruteForce', 'dos', 'pingScan', 'portScan'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'Columns of data_y (and confusion matrix): {data_y.columns}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47dc783c64eba16578308ded2496eecd3f77c9cbf1d7b090711421ceeb34a226"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
