{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%cd ../../.."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Users\\bram_\\home\\msc\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The big test v2: remove all but 25% `bruteForce` flow from week1 and all but 25% `pingScan` flow from week2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# from IPython.display import clear_output\r\n",
    "\r\n",
    "# tensorflow_federated_nightly also bring in tf_nightly, which\r\n",
    "# can causes a duplicate tensorboard install, leading to errors.\r\n",
    "# !pip uninstall --yes tensorboard tb-nightly\r\n",
    "\r\n",
    "# !pip install --upgrade tensorflow-federated-nightly\r\n",
    "# !pip install --upgrade nest-asyncio\r\n",
    "# !pip install --upgrade tb-nightly\r\n",
    "\r\n",
    "import nest_asyncio\r\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# TensorFlow and tf.keras\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_federated as tff\r\n",
    "\r\n",
    "# Helper libraries\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import collections\r\n",
    "\r\n",
    "from utils import cidds_001 as utils\r\n",
    "from utils.tff_test import TffClientDataProvider\r\n",
    "\r\n",
    "print(tf.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare the datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and shuffle datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# load and shuffle week1\r\n",
    "week1 = pd.read_feather('saved_dfs/cidds-001/traffic/OpenStack/CIDDS-001-internal-week1-cleaned.feather')\r\n",
    "week1_shuffled = week1.sample(frac=1, random_state=13).reset_index(drop=True)\r\n",
    "\r\n",
    "# load and shuffle week2\r\n",
    "week2 = pd.read_feather('saved_dfs/cidds-001/traffic/OpenStack/CIDDS-001-internal-week2-cleaned.feather')\r\n",
    "week2_shuffled = week2.sample(frac=1, random_state=13).reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtain a ClientData object"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "client_data_provider = TffClientDataProvider(\r\n",
    "    week1=week1_shuffled,\r\n",
    "    week2=week2_shuffled,\r\n",
    "    drop_target1='bruteForce',\r\n",
    "    drop_target2='pingScan',\r\n",
    "    alpha_target1=0.25,\r\n",
    "    alpha_target2=0.25,\r\n",
    "    normalization_fn=utils.z_score_normalization,\r\n",
    "    random_state=13\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start preprocessing datasets week1 and week2\n",
      "0.0s: Normalizing week1 and week2\n",
      "7.33s: Creating balanced dataset of week1\n",
      "63.7s: Creating balanced dataset of week2\n",
      "125.0s: Removing 75.0% of bruteForce flows from week1\n",
      "125.1s: Removing 75.0% of pingScan flows from week2\n",
      "125.18s: Separate week1 features from dataset labels and one hot encode the labels\n",
      "125.19s: Separate week2 features from dataset labels and one hot encode the labels\n",
      "125.2s: Split datasets in training and testing datasets\n",
      "125.22s: Convert features and labels to numpy arrays\n",
      "125.22s: Finished preprocessing datasets week1 and week2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "client_data = client_data_provider.make_client_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Confirm having created balanced datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "pd.DataFrame(client_data_provider.week1_balanced.groupby(by='attack_type').size(), columns=['count']).reset_index()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  attack_type  count\n",
       "0         ---   3359\n",
       "1  bruteForce    406\n",
       "2         dos   3359\n",
       "3    pingScan   3359\n",
       "4    portScan   3359"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attack_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---</td>\n",
       "      <td>3359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bruteForce</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dos</td>\n",
       "      <td>3359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pingScan</td>\n",
       "      <td>3359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>portScan</td>\n",
       "      <td>3359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "pd.DataFrame(client_data_provider.week2_balanced.groupby(by='attack_type').size(), columns=['count']).reset_index()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  attack_type  count\n",
       "0         ---   3366\n",
       "1  bruteForce   3366\n",
       "2         dos   3366\n",
       "3    pingScan    682\n",
       "4    portScan   3366"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attack_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---</td>\n",
       "      <td>3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bruteForce</td>\n",
       "      <td>3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dos</td>\n",
       "      <td>3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pingScan</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>portScan</td>\n",
       "      <td>3366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparation for the federated part"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the `federated_train_data`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "NUM_EPOCHS = 5\r\n",
    "BATCH_SIZE = 20\r\n",
    "SHUFFLE_BUFFER = 100\r\n",
    "PREFETCH_BUFFER = 10\r\n",
    "\r\n",
    "def preprocess(dataset):\r\n",
    "    def batch_format_fn(x, y):\r\n",
    "        return collections.OrderedDict(\r\n",
    "            x=x,\r\n",
    "            y=y\r\n",
    "        )\r\n",
    "    \r\n",
    "    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\r\n",
    "        BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def make_federated_data(client_data, client_ids):\r\n",
    "    return [\r\n",
    "        preprocess(client_data.create_tf_dataset_for_client(x))\r\n",
    "        for x in client_ids\r\n",
    "    ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "client_ids = client_data.client_ids\r\n",
    "federated_train_data = make_federated_data(client_data, client_ids)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtain the element_spec of the input that the federated model will receive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "preprocessed_example_data = federated_train_data[0]\r\n",
    "tff_input_element_spec = preprocessed_example_data.element_spec"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create functions to create the TFF model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def create_keras_model():\r\n",
    "    return tf.keras.Sequential([\r\n",
    "        tf.keras.layers.Input(shape=(16,)),\r\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\r\n",
    "        tf.keras.layers.Dropout(rate=0.2),\r\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\r\n",
    "        tf.keras.layers.Dropout(rate=0.2),\r\n",
    "        tf.keras.layers.Dense(5, activation='softmax')\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def model_fn():\r\n",
    "    keras_model = create_keras_model()\r\n",
    "    return tff.learning.from_keras_model(\r\n",
    "        keras_model,\r\n",
    "        input_spec=tff_input_element_spec,\r\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\r\n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.CategoricalCrossentropy()]\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model on federated data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\r\n",
    "    model_fn=model_fn,\r\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\r\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bram_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "str(iterative_process.initialize.type_signature)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'( -> <model=<trainable=<float32[16,100],float32[100],float32[100,100],float32[100],float32[100,5],float32[5]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "state = iterative_process.initialize()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "NUM_ROUNDS = 20\r\n",
    "for round_num in range(NUM_ROUNDS):\r\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\r\n",
    "  print('round {:2d}, metrics={}'.format(round_num+1, metrics))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.8580374), ('categorical_crossentropy', 0.42822906), ('loss', 0.42802975)]))])\n",
      "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.90100497), ('categorical_crossentropy', 0.28365326), ('loss', 0.283581)]))])\n",
      "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.9096253), ('categorical_crossentropy', 0.258654), ('loss', 0.258654)]))])\n",
      "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.91482425), ('categorical_crossentropy', 0.24343069), ('loss', 0.24343066)]))])\n",
      "round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.9191299), ('categorical_crossentropy', 0.23272574), ('loss', 0.2326313)]))])\n",
      "round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.9222475), ('categorical_crossentropy', 0.22420256), ('loss', 0.2241446)]))])\n",
      "round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.92365), ('categorical_crossentropy', 0.21719357), ('loss', 0.21719357)]))])\n",
      "round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.9256599), ('categorical_crossentropy', 0.21155618), ('loss', 0.21149696)]))])\n",
      "round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.9281343), ('categorical_crossentropy', 0.20614699), ('loss', 0.20614696)]))])\n",
      "round 10, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.9287329), ('categorical_crossentropy', 0.20208128), ('loss', 0.20177414)]))])\n",
      "round 11, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.9303944), ('categorical_crossentropy', 0.19888236), ('loss', 0.19884136)]))])\n",
      "round 12, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.93242216), ('categorical_crossentropy', 0.19391268), ('loss', 0.19391268)]))])\n",
      "round 13, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.93325293), ('categorical_crossentropy', 0.19096714), ('loss', 0.19096714)]))])\n",
      "round 14, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.9347805), ('categorical_crossentropy', 0.18870838), ('loss', 0.18844718)]))])\n",
      "round 15, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.9358346), ('categorical_crossentropy', 0.1850687), ('loss', 0.1850682)]))])\n",
      "round 16, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.93607575), ('categorical_crossentropy', 0.18283404), ('loss', 0.18274257)]))])\n",
      "round 17, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.93679935), ('categorical_crossentropy', 0.18036652), ('loss', 0.18036652)]))])\n",
      "round 18, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.93761224), ('categorical_crossentropy', 0.17778449), ('loss', 0.17776388)]))])\n",
      "round 19, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.93631697), ('categorical_crossentropy', 0.17877923), ('loss', 0.17837913)]))])\n",
      "round 20, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', OrderedDict([('categorical_accuracy', 0.93922013), ('categorical_crossentropy', 0.17401458), ('loss', 0.17401458)]))])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the global model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "model = create_keras_model()\r\n",
    "state.model.assign_weights_to(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Concatenate test sets from week1 and week2 to obtain a bigger test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "test_x = np.concatenate([client_data_provider.x_test_week1, client_data_provider.x_test_week2])\r\n",
    "test_y = np.concatenate([client_data_provider.y_test_week1, client_data_provider.y_test_week2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assign the federated trained weights to a model that can be used"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict the test set and create a confusion matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "pred_y = model.predict(test_x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "y_lbl = np.argmax(test_y, axis=1)\r\n",
    "pred_y_lbl = np.argmax(pred_y, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "tf.math.confusion_matrix(labels=y_lbl, predictions=pred_y_lbl, num_classes=5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[1234,   40,    5,    1,    3],\n",
       "       [   9,  616,    0,    4,  140],\n",
       "       [   1,    0, 1359,    0,    0],\n",
       "       [  22,   10,    0,  746,    1],\n",
       "       [  28,   47,    0,   55, 1278]])>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "len(y_lbl)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5599"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "client_data_provider.ohe_columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['---', 'bruteForce', 'dos', 'pingScan', 'portScan'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the global model with the training data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "train_x = np.concatenate([client_data_provider.x_train_week1, client_data_provider.x_train_week2])\r\n",
    "train_y = np.concatenate([client_data_provider.y_train_week1, client_data_provider.y_train_week2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "pred_y = model.predict(train_x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "y_lbl = np.argmax(train_y, axis=1)\r\n",
    "pred_y_lbl = np.argmax(pred_y, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "tf.math.confusion_matrix(labels=y_lbl, predictions=pred_y_lbl, num_classes=5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[5225,  151,   38,    5,   23],\n",
       "       [  48, 2445,    0,   11,  499],\n",
       "       [   6,    0, 5359,    0,    0],\n",
       "       [  80,   54,    0, 3118,   10],\n",
       "       [  81,  198,    0,  216, 4822]])>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "len(y_lbl)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22389"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "47dc783c64eba16578308ded2496eecd3f77c9cbf1d7b090711421ceeb34a226"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}